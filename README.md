# IzakayaSearch
居酒屋
クローラーとスクレイピングは同義語

## やることリスト

- スクレイピングのやり方を調べる
  - 1つのサイトからそもそもどのように情報を持ってくるのかを調べる
  - それができたら複数のサイトでスクレイピングして情報がどのように手に入るのかを模索する
  - それらの情報をもとにどのお店が1番安いのかを求める
- どのサイトを参照するか
  - 参照したサイトからどうやって情報を持ってくるか
- 情報の信頼性を高めるにはどうすればよいか

## クローラーとは？
システムが自動的にWebページを巡回して情報を収集するプログラムのことをクローラー(Crawler＝這いずり回るもの？)と言います。

代表的なクローラーはGoogleのGooglebotで、Googleはこれを使って予め世界中(Web上)のあらゆる情報を取得し、それぞれに目印をつけて置きます。
Googleの検索窓にユーザーがキーワードを打ち込んだ（ググった）際、その目印などを元に「このキーワードでググった人が欲しい情報は何か」を、Googleのアルゴリズムが自動で判断し、ユーザーに取って便利だと思う順に並び替えて、検索結果としてPCやスマホの画面に表示します。

## クローラーの挙動の分解
クローラーの挙動については、大きく以下の3つに分けられます。

1. コンテンツの取得（ダウンロード）  
　サイトにアクセスし、HTMLなどをページ分全てダウンロードする　　　
1. データの解析（≒分解）  
　ダウンロードしたページを要素(タグ等)に解析し、そのうち欲しいデータを取得する(抜き出し加工する)
1. ③データの保存  
　①と②によって取得したものをデータベースなどに保存する

この一連の流れ(主に①・②)を繰り返していくことをクローリングと言います。  
例えば、②で、そのページ上の欲しい情報に加えてリンク(URL)の取得も行うことで、  
「①取得したリンク先にアクセス」→「②解析して欲しいデータを取得＆次アクセスしたいページのリンクを取得」→「①取得したリンク先にアクセス」→…
と自動で繰り返し、どんどん欲しい情報を集めることが出来たりします。

この②解析の際に、例えば「<a>タグ」だったり「id="hogehoge"のもの」だったりと、欲しい情報を持っている要素を指定してあげることで、自由に情報を取得することが出来ます。
下のようなHTMLファイルを持つページであれば、例えば「<p>タグで且つid="hoge"のもの」と指定すれば、欲しい情報を取得出来ます。

## ファイルの実行の仕方
`node start`
